{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bank_customer_churn_prediction",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNkhknkpbHpRuqou1vyfgPn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SonalikaSingh/Bank_customer_churning/blob/main/Bank_customer_churn_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq4c_JKMWer2"
      },
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "WGnOtjaXXKM3",
        "outputId": "618aa8b8-0e1b-4ecd-af70-a6a6d23d333c"
      },
      "source": [
        "df = pd.read_csv(\"Churn_Modelling.csv\")\n",
        "df.sample(5)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5909</th>\n",
              "      <td>5910</td>\n",
              "      <td>15713043</td>\n",
              "      <td>Siciliani</td>\n",
              "      <td>691</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>33</td>\n",
              "      <td>6</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>100408.31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3605</th>\n",
              "      <td>3606</td>\n",
              "      <td>15788683</td>\n",
              "      <td>Kang</td>\n",
              "      <td>588</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Female</td>\n",
              "      <td>34</td>\n",
              "      <td>10</td>\n",
              "      <td>129417.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>153727.32</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6008</th>\n",
              "      <td>6009</td>\n",
              "      <td>15700937</td>\n",
              "      <td>Romano</td>\n",
              "      <td>767</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>24</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>67445.85</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5234</th>\n",
              "      <td>5235</td>\n",
              "      <td>15668323</td>\n",
              "      <td>Mbadiwe</td>\n",
              "      <td>678</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>143443.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>196622.28</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8979</th>\n",
              "      <td>8980</td>\n",
              "      <td>15742511</td>\n",
              "      <td>Gordon</td>\n",
              "      <td>514</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>3</td>\n",
              "      <td>121030.90</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10008.68</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      RowNumber  CustomerId    Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "5909       5910    15713043  Siciliani  ...               1       100408.31      0\n",
              "3605       3606    15788683       Kang  ...               0       153727.32      0\n",
              "6008       6009    15700937     Romano  ...               1        67445.85      0\n",
              "5234       5235    15668323    Mbadiwe  ...               0       196622.28      1\n",
              "8979       8980    15742511     Gordon  ...               0        10008.68      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlWbjfuc72Ut"
      },
      "source": [
        "Checking if the dataset is imbalanced or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1f5CB0z7tvg",
        "outputId": "d60b6d51-f936-4e1d-be49-fedcb1518a83"
      },
      "source": [
        "df.Exited.value_counts()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7963\n",
              "1    2037\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc8xRJpYuxcT"
      },
      "source": [
        "df.drop(['RowNumber','CustomerId','Surname'],axis='columns',inplace=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ApSQl9DvN3K"
      },
      "source": [
        "We can use seaborn to create a simple heatmap to see where data is missing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "1-aAJ3dRvLcb",
        "outputId": "0786ba7e-0491-4ff0-8097-300e2660d32e"
      },
      "source": [
        "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0e8374ae50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ0zMPiWYgBy",
        "outputId": "53207d60-cc28-4953-eed5-25c817047bee"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CreditScore          int64\n",
              "Geography           object\n",
              "Gender              object\n",
              "Age                  int64\n",
              "Tenure               int64\n",
              "Balance            float64\n",
              "NumOfProducts        int64\n",
              "HasCrCard            int64\n",
              "IsActiveMember       int64\n",
              "EstimatedSalary    float64\n",
              "Exited               int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzKicOT1v6Qk"
      },
      "source": [
        "Changing datatype of gender to int"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9l2LzuHYqBV"
      },
      "source": [
        "df['Gender'].replace({'Female':1,'Male':0},inplace=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pthf2k4TwDmF"
      },
      "source": [
        "Dummy variables to convert geography object into int"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RaPKGC-v_Pm"
      },
      "source": [
        "x=pd.get_dummies(df.Geography)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEn46yeCweI-"
      },
      "source": [
        "#Concatenation in pandas to join two dataframes\n",
        "merged=pd.concat([df,x],axis='columns')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQCZ4DDBwub8"
      },
      "source": [
        "#Dropping original geography column\n",
        "final=merged.drop('Geography',axis='columns')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "8OWHruyCxRUw",
        "outputId": "4bcd0028-7fed-4ec0-9009-8c59852a7099"
      },
      "source": [
        "final.head(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>France</th>\n",
              "      <th>Germany</th>\n",
              "      <th>Spain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore  Gender  Age  Tenure  ...  Exited  France  Germany  Spain\n",
              "0          619       1   42       2  ...       1       1        0      0\n",
              "1          608       1   41       1  ...       0       0        0      1\n",
              "2          502       1   42       8  ...       1       1        0      0\n",
              "3          699       1   39       1  ...       0       1        0      0\n",
              "4          850       1   43       2  ...       0       0        0      1\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQrXPgjixpq0"
      },
      "source": [
        "Machine learns better if values are between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0XPon8KcoW8"
      },
      "source": [
        "cols_to_scale = ['CreditScore','Age','Tenure','Balance','EstimatedSalary','NumOfProducts']\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "final[cols_to_scale] = scaler.fit_transform(final[cols_to_scale])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "rBTM4P0ddcbL",
        "outputId": "b30130f6-a34e-40c8-bfd8-94b6156a4a5a"
      },
      "source": [
        "final.head(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>France</th>\n",
              "      <th>Germany</th>\n",
              "      <th>Spain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.538</td>\n",
              "      <td>1</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.506735</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.516</td>\n",
              "      <td>1</td>\n",
              "      <td>0.310811</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.334031</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.562709</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.304</td>\n",
              "      <td>1</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.636357</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.569654</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.698</td>\n",
              "      <td>1</td>\n",
              "      <td>0.283784</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469120</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.337838</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.500246</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.395400</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore  Gender       Age  Tenure  ...  Exited  France  Germany  Spain\n",
              "0        0.538       1  0.324324     0.2  ...       1       1        0      0\n",
              "1        0.516       1  0.310811     0.1  ...       0       0        0      1\n",
              "2        0.304       1  0.324324     0.8  ...       1       1        0      0\n",
              "3        0.698       1  0.283784     0.1  ...       0       1        0      0\n",
              "4        1.000       1  0.337838     0.2  ...       0       0        0      1\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFr3XgsFdfeC"
      },
      "source": [
        "X = final.drop('Exited',axis='columns')\n",
        "y = final['Exited']\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "acChczAFd5_q",
        "outputId": "9fbcbf7f-7416-4850-dfc3-70a167817506"
      },
      "source": [
        "X_train[:5]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>France</th>\n",
              "      <th>Germany</th>\n",
              "      <th>Spain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7751</th>\n",
              "      <td>0.800</td>\n",
              "      <td>1</td>\n",
              "      <td>0.283784</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.096273</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4154</th>\n",
              "      <td>0.752</td>\n",
              "      <td>0</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.981478</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3881</th>\n",
              "      <td>0.476</td>\n",
              "      <td>1</td>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.948551</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9238</th>\n",
              "      <td>0.846</td>\n",
              "      <td>1</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.646869</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5210</th>\n",
              "      <td>0.402</td>\n",
              "      <td>0</td>\n",
              "      <td>0.229730</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.517012</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.434670</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CreditScore  Gender       Age  ...  France  Germany  Spain\n",
              "7751        0.800       1  0.283784  ...       0        0      1\n",
              "4154        0.752       0  0.216216  ...       1        0      0\n",
              "3881        0.476       1  0.621622  ...       1        0      0\n",
              "9238        0.846       1  0.432432  ...       1        0      0\n",
              "5210        0.402       0  0.229730  ...       1        0      0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RQPZKTWeh6c",
        "outputId": "723a4b36-fa74-4a8a-d647-99cfc0e80add"
      },
      "source": [
        "len(X_train.columns)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Am5uExE8hf4"
      },
      "source": [
        "Building ANN model in keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg3UBPhtevuM"
      },
      "source": [
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import confusion_matrix , classification_report\n",
        "\n",
        "def ANN(X_train, y_train, X_test, y_test, loss, weights):\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(26, input_dim=12, activation='relu'),\n",
        "        keras.layers.Dense(15, activation='relu'),\n",
        "        keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
        "    \n",
        "    if weights == -1:\n",
        "        model.fit(X_train, y_train, epochs=100)\n",
        "    else:\n",
        "        model.fit(X_train, y_train, epochs=100, class_weight = weights)\n",
        "    \n",
        "    print(model.evaluate(X_test, y_test))\n",
        "    \n",
        "    y_preds = model.predict(X_test)\n",
        "    y_preds = np.round(y_preds)\n",
        "    \n",
        "    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n",
        "    \n",
        "    return y_preds"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikHMslho8-_q",
        "outputId": "42ab660a-429a-48e3-b27c-a769c1f6572c"
      },
      "source": [
        "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 1s 944us/step - loss: 0.5221 - accuracy: 0.7653\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 0s 926us/step - loss: 0.4597 - accuracy: 0.8040\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 0s 989us/step - loss: 0.4432 - accuracy: 0.8087\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 0s 882us/step - loss: 0.4316 - accuracy: 0.8146\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.4229 - accuracy: 0.8196\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 0s 974us/step - loss: 0.4132 - accuracy: 0.8250\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 0s 955us/step - loss: 0.4027 - accuracy: 0.8280\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.3917 - accuracy: 0.8329\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 0s 951us/step - loss: 0.3837 - accuracy: 0.8400\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 0s 991us/step - loss: 0.3737 - accuracy: 0.8440\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 0s 931us/step - loss: 0.3694 - accuracy: 0.8481\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 0s 932us/step - loss: 0.3636 - accuracy: 0.8499\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 0s 937us/step - loss: 0.3598 - accuracy: 0.8509\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 0s 944us/step - loss: 0.3564 - accuracy: 0.8529\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 0s 989us/step - loss: 0.3536 - accuracy: 0.8549\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 0s 937us/step - loss: 0.3524 - accuracy: 0.8524\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 0s 948us/step - loss: 0.3495 - accuracy: 0.8572\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.3489 - accuracy: 0.8537\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.3480 - accuracy: 0.8554\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 0s 993us/step - loss: 0.3468 - accuracy: 0.8566\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8581\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3455 - accuracy: 0.8561\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 0s 917us/step - loss: 0.3426 - accuracy: 0.8593\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 0s 924us/step - loss: 0.3427 - accuracy: 0.8585\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 0s 926us/step - loss: 0.3417 - accuracy: 0.8586\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 0s 917us/step - loss: 0.3412 - accuracy: 0.8589\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 0s 941us/step - loss: 0.3388 - accuracy: 0.8614\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 0s 917us/step - loss: 0.3408 - accuracy: 0.8601\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 0s 953us/step - loss: 0.3396 - accuracy: 0.8605\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 0s 933us/step - loss: 0.3381 - accuracy: 0.8600\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 0s 971us/step - loss: 0.3403 - accuracy: 0.8589\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3383 - accuracy: 0.8586\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 0s 930us/step - loss: 0.3396 - accuracy: 0.8585\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 0s 907us/step - loss: 0.3373 - accuracy: 0.8620\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 0s 931us/step - loss: 0.3363 - accuracy: 0.8626\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 0s 954us/step - loss: 0.3361 - accuracy: 0.8609\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 0s 908us/step - loss: 0.3361 - accuracy: 0.8621\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 0s 935us/step - loss: 0.3352 - accuracy: 0.8620\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 0s 906us/step - loss: 0.3353 - accuracy: 0.8621\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 0s 934us/step - loss: 0.3348 - accuracy: 0.8625\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 0s 924us/step - loss: 0.3338 - accuracy: 0.8620\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 0s 957us/step - loss: 0.3350 - accuracy: 0.8614\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 0s 946us/step - loss: 0.3338 - accuracy: 0.8630\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 0s 967us/step - loss: 0.3348 - accuracy: 0.8656\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 0s 966us/step - loss: 0.3332 - accuracy: 0.8635\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 0s 944us/step - loss: 0.3325 - accuracy: 0.8633\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 0s 968us/step - loss: 0.3325 - accuracy: 0.8631\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 0s 927us/step - loss: 0.3322 - accuracy: 0.8644\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 0s 989us/step - loss: 0.3313 - accuracy: 0.8661\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 0s 972us/step - loss: 0.3325 - accuracy: 0.8650\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 0s 983us/step - loss: 0.3310 - accuracy: 0.8655\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 0s 955us/step - loss: 0.3301 - accuracy: 0.8654\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.3318 - accuracy: 0.8639\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 0s 944us/step - loss: 0.3301 - accuracy: 0.8659\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8643\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 0s 969us/step - loss: 0.3304 - accuracy: 0.8646\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8639\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 0s 930us/step - loss: 0.3304 - accuracy: 0.8619\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 0s 922us/step - loss: 0.3298 - accuracy: 0.8645\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 0s 924us/step - loss: 0.3298 - accuracy: 0.8649\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 0s 956us/step - loss: 0.3287 - accuracy: 0.8655\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 0s 971us/step - loss: 0.3285 - accuracy: 0.8652\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 0s 909us/step - loss: 0.3287 - accuracy: 0.8651\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 0s 939us/step - loss: 0.3296 - accuracy: 0.8666\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 0s 964us/step - loss: 0.3283 - accuracy: 0.8650\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 0s 959us/step - loss: 0.3284 - accuracy: 0.8660\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8652\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 0s 913us/step - loss: 0.3278 - accuracy: 0.8658\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 0s 973us/step - loss: 0.3276 - accuracy: 0.8652\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 0s 956us/step - loss: 0.3262 - accuracy: 0.8656\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3268 - accuracy: 0.8671\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 0s 994us/step - loss: 0.3270 - accuracy: 0.8670\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 0s 962us/step - loss: 0.3277 - accuracy: 0.8670\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 0s 952us/step - loss: 0.3259 - accuracy: 0.8673\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 0s 897us/step - loss: 0.3277 - accuracy: 0.8648\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 0s 884us/step - loss: 0.3270 - accuracy: 0.8652\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 0s 980us/step - loss: 0.3257 - accuracy: 0.8677\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 0s 927us/step - loss: 0.3259 - accuracy: 0.8662\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 0s 924us/step - loss: 0.3254 - accuracy: 0.8670\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 0s 914us/step - loss: 0.3263 - accuracy: 0.8666\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3241 - accuracy: 0.8695\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 0s 924us/step - loss: 0.3251 - accuracy: 0.8680\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 0s 980us/step - loss: 0.3247 - accuracy: 0.8677\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 0s 922us/step - loss: 0.3249 - accuracy: 0.8676\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3234 - accuracy: 0.8668\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3242 - accuracy: 0.8660\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 0s 960us/step - loss: 0.3240 - accuracy: 0.8709\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.3249 - accuracy: 0.8665\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3243 - accuracy: 0.8681\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 0s 933us/step - loss: 0.3241 - accuracy: 0.8671\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 0s 972us/step - loss: 0.3259 - accuracy: 0.8665\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.3233 - accuracy: 0.8686\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3230 - accuracy: 0.8700\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 0s 991us/step - loss: 0.3228 - accuracy: 0.8660\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 0s 977us/step - loss: 0.3242 - accuracy: 0.8662\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 0s 961us/step - loss: 0.3254 - accuracy: 0.8675\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 0s 986us/step - loss: 0.3239 - accuracy: 0.8662\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 0s 952us/step - loss: 0.3224 - accuracy: 0.8695\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 0s 984us/step - loss: 0.3223 - accuracy: 0.8669\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 0s 995us/step - loss: 0.3225 - accuracy: 0.8669\n",
            "63/63 [==============================] - 0s 714us/step - loss: 0.3590 - accuracy: 0.8500\n",
            "[0.3590201139450073, 0.8500000238418579]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91      1595\n",
            "           1       0.69      0.47      0.56       405\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.78      0.71      0.74      2000\n",
            "weighted avg       0.84      0.85      0.84      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhK__5uz9P8I"
      },
      "source": [
        "**Handelling Imbalanced dataset**\n",
        "**METHOD1:UNDERSAMPLING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "WhAkiGzir7Ox",
        "outputId": "7b244a1d-f154-447f-aaec-7e986f4912eb"
      },
      "source": [
        "final_class_0"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>France</th>\n",
              "      <th>Germany</th>\n",
              "      <th>Spain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.516</td>\n",
              "      <td>1</td>\n",
              "      <td>0.310811</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.334031</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.562709</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.698</td>\n",
              "      <td>1</td>\n",
              "      <td>0.283784</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469120</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.337838</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.500246</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.395400</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.944</td>\n",
              "      <td>0</td>\n",
              "      <td>0.432432</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.050261</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.302</td>\n",
              "      <td>0</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.566170</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.374680</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9993</th>\n",
              "      <td>0.588</td>\n",
              "      <td>0</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.618021</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.145854</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9994</th>\n",
              "      <td>0.900</td>\n",
              "      <td>1</td>\n",
              "      <td>0.148649</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.838890</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0.842</td>\n",
              "      <td>0</td>\n",
              "      <td>0.283784</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.481341</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>0.332</td>\n",
              "      <td>0</td>\n",
              "      <td>0.229730</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.228657</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.508490</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0.884</td>\n",
              "      <td>1</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.518708</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.190914</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7963 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      CreditScore  Gender       Age  Tenure  ...  Exited  France  Germany  Spain\n",
              "1           0.516       1  0.310811     0.1  ...       0       0        0      1\n",
              "3           0.698       1  0.283784     0.1  ...       0       1        0      0\n",
              "4           1.000       1  0.337838     0.2  ...       0       0        0      1\n",
              "6           0.944       0  0.432432     0.7  ...       0       1        0      0\n",
              "8           0.302       0  0.351351     0.4  ...       0       1        0      0\n",
              "...           ...     ...       ...     ...  ...     ...     ...      ...    ...\n",
              "9993        0.588       0  0.135135     0.7  ...       0       1        0      0\n",
              "9994        0.900       1  0.148649     0.2  ...       0       1        0      0\n",
              "9995        0.842       0  0.283784     0.5  ...       0       1        0      0\n",
              "9996        0.332       0  0.229730     1.0  ...       0       1        0      0\n",
              "9999        0.884       1  0.135135     0.4  ...       0       1        0      0\n",
              "\n",
              "[7963 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW3nh8S72iKB",
        "outputId": "bbfb8e45-e7cd-4630-ed5e-8ff484e6da62"
      },
      "source": [
        "final.Exited.value_counts()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7963\n",
              "1    2037\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05VgIToE97NY"
      },
      "source": [
        "\n",
        "# Class count\n",
        "count_class_0, count_class_1 = final.Exited.value_counts()\n",
        "\n",
        "# Divide by class\n",
        "final_class_0 = final[final['Exited'] == 0]\n",
        "final_class_1 = final[final['Exited'] == 1]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e-e7Rdf9ajX",
        "outputId": "2d849603-8002-44b1-b2ea-50288e7a8f4e"
      },
      "source": [
        "# Undersample 0-class and concat the DataFrames of both class\n",
        "final_class_0_under = final_class_0.sample(count_class_1)\n",
        "final_test_under = pd.concat([final_class_0_under, final_class_1], axis=0)\n",
        "print('Random under-sampling:')\n",
        "print(final_test_under.Exited.value_counts())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random under-sampling:\n",
            "1    2037\n",
            "0    2037\n",
            "Name: Exited, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tee7En8v92pR"
      },
      "source": [
        "X = final_test_under.drop('Exited',axis='columns')\n",
        "y = final_test_under['Exited']\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BP1AhR9I-Y5G",
        "outputId": "bb5d8f14-9328-45ec-e39e-efe8810f4e56"
      },
      "source": [
        "# Number of classes in training Data\n",
        "y_train.value_counts()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1630\n",
              "0    1629\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itfbRnto-cA3",
        "outputId": "2cb98376-0682-4066-d8e0-73964fefbd9c"
      },
      "source": [
        "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5529\n",
            "Epoch 2/100\n",
            "102/102 [==============================] - 0s 972us/step - loss: 0.6512 - accuracy: 0.6468\n",
            "Epoch 3/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.6285 - accuracy: 0.6628\n",
            "Epoch 4/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.6175 - accuracy: 0.6640\n",
            "Epoch 5/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.6055 - accuracy: 0.6800\n",
            "Epoch 6/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5990 - accuracy: 0.6784\n",
            "Epoch 7/100\n",
            "102/102 [==============================] - 0s 973us/step - loss: 0.5895 - accuracy: 0.6886\n",
            "Epoch 8/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5844 - accuracy: 0.6944\n",
            "Epoch 9/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5794 - accuracy: 0.7021\n",
            "Epoch 10/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5742 - accuracy: 0.7033\n",
            "Epoch 11/100\n",
            "102/102 [==============================] - 0s 977us/step - loss: 0.5700 - accuracy: 0.7119\n",
            "Epoch 12/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5656 - accuracy: 0.7100\n",
            "Epoch 13/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5617 - accuracy: 0.7100\n",
            "Epoch 14/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5567 - accuracy: 0.7220\n",
            "Epoch 15/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5540 - accuracy: 0.7208\n",
            "Epoch 16/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5501 - accuracy: 0.7238\n",
            "Epoch 17/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5437 - accuracy: 0.7288\n",
            "Epoch 18/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5393 - accuracy: 0.7340\n",
            "Epoch 19/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5350 - accuracy: 0.7343\n",
            "Epoch 20/100\n",
            "102/102 [==============================] - 0s 965us/step - loss: 0.5294 - accuracy: 0.7367\n",
            "Epoch 21/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5254 - accuracy: 0.7392\n",
            "Epoch 22/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5197 - accuracy: 0.7444\n",
            "Epoch 23/100\n",
            "102/102 [==============================] - 0s 926us/step - loss: 0.5154 - accuracy: 0.7478\n",
            "Epoch 24/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5095 - accuracy: 0.7530\n",
            "Epoch 25/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7591\n",
            "Epoch 26/100\n",
            "102/102 [==============================] - 0s 946us/step - loss: 0.4989 - accuracy: 0.7610\n",
            "Epoch 27/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.7628\n",
            "Epoch 28/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.7650\n",
            "Epoch 29/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.7585\n",
            "Epoch 30/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.7705\n",
            "Epoch 31/100\n",
            "102/102 [==============================] - 0s 989us/step - loss: 0.4821 - accuracy: 0.7689\n",
            "Epoch 32/100\n",
            "102/102 [==============================] - 0s 973us/step - loss: 0.4825 - accuracy: 0.7653\n",
            "Epoch 33/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7686\n",
            "Epoch 34/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7677\n",
            "Epoch 35/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4767 - accuracy: 0.7656\n",
            "Epoch 36/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7699\n",
            "Epoch 37/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7699\n",
            "Epoch 38/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7772\n",
            "Epoch 39/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.7766\n",
            "Epoch 40/100\n",
            "102/102 [==============================] - 0s 974us/step - loss: 0.4674 - accuracy: 0.7751\n",
            "Epoch 41/100\n",
            "102/102 [==============================] - 0s 960us/step - loss: 0.4673 - accuracy: 0.7778\n",
            "Epoch 42/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7739\n",
            "Epoch 43/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.7742\n",
            "Epoch 44/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7748\n",
            "Epoch 45/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.7723\n",
            "Epoch 46/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7760\n",
            "Epoch 47/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7769\n",
            "Epoch 48/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7778\n",
            "Epoch 49/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7803\n",
            "Epoch 50/100\n",
            "102/102 [==============================] - 0s 946us/step - loss: 0.4625 - accuracy: 0.7763\n",
            "Epoch 51/100\n",
            "102/102 [==============================] - 0s 991us/step - loss: 0.4621 - accuracy: 0.7760\n",
            "Epoch 52/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7757\n",
            "Epoch 53/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7834\n",
            "Epoch 54/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7778\n",
            "Epoch 55/100\n",
            "102/102 [==============================] - 0s 954us/step - loss: 0.4581 - accuracy: 0.7791\n",
            "Epoch 56/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7821\n",
            "Epoch 57/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4566 - accuracy: 0.7818\n",
            "Epoch 58/100\n",
            "102/102 [==============================] - 0s 948us/step - loss: 0.4550 - accuracy: 0.7855\n",
            "Epoch 59/100\n",
            "102/102 [==============================] - 0s 917us/step - loss: 0.4564 - accuracy: 0.7772\n",
            "Epoch 60/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.7852\n",
            "Epoch 61/100\n",
            "102/102 [==============================] - 0s 958us/step - loss: 0.4555 - accuracy: 0.7828\n",
            "Epoch 62/100\n",
            "102/102 [==============================] - 0s 938us/step - loss: 0.4550 - accuracy: 0.7824\n",
            "Epoch 63/100\n",
            "102/102 [==============================] - 0s 922us/step - loss: 0.4561 - accuracy: 0.7821\n",
            "Epoch 64/100\n",
            "102/102 [==============================] - 0s 960us/step - loss: 0.4551 - accuracy: 0.7800\n",
            "Epoch 65/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7806\n",
            "Epoch 66/100\n",
            "102/102 [==============================] - 0s 967us/step - loss: 0.4508 - accuracy: 0.7880\n",
            "Epoch 67/100\n",
            "102/102 [==============================] - 0s 965us/step - loss: 0.4523 - accuracy: 0.7800\n",
            "Epoch 68/100\n",
            "102/102 [==============================] - 0s 906us/step - loss: 0.4526 - accuracy: 0.7828\n",
            "Epoch 69/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.7843\n",
            "Epoch 70/100\n",
            "102/102 [==============================] - 0s 973us/step - loss: 0.4525 - accuracy: 0.7828\n",
            "Epoch 71/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7840\n",
            "Epoch 72/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7867\n",
            "Epoch 73/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7858\n",
            "Epoch 74/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.7800\n",
            "Epoch 75/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7871\n",
            "Epoch 76/100\n",
            "102/102 [==============================] - 0s 981us/step - loss: 0.4468 - accuracy: 0.7858\n",
            "Epoch 77/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.7886\n",
            "Epoch 78/100\n",
            "102/102 [==============================] - 0s 948us/step - loss: 0.4479 - accuracy: 0.7880\n",
            "Epoch 79/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7864\n",
            "Epoch 80/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7892\n",
            "Epoch 81/100\n",
            "102/102 [==============================] - 0s 963us/step - loss: 0.4449 - accuracy: 0.7837\n",
            "Epoch 82/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.7846\n",
            "Epoch 83/100\n",
            "102/102 [==============================] - 0s 981us/step - loss: 0.4455 - accuracy: 0.7904\n",
            "Epoch 84/100\n",
            "102/102 [==============================] - 0s 931us/step - loss: 0.4449 - accuracy: 0.7904\n",
            "Epoch 85/100\n",
            "102/102 [==============================] - 0s 944us/step - loss: 0.4447 - accuracy: 0.7883\n",
            "Epoch 86/100\n",
            "102/102 [==============================] - 0s 940us/step - loss: 0.4427 - accuracy: 0.7849\n",
            "Epoch 87/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.7907\n",
            "Epoch 88/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7904\n",
            "Epoch 89/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.7895\n",
            "Epoch 90/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7917\n",
            "Epoch 91/100\n",
            "102/102 [==============================] - 0s 988us/step - loss: 0.4444 - accuracy: 0.7880\n",
            "Epoch 92/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7926\n",
            "Epoch 93/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4417 - accuracy: 0.7858\n",
            "Epoch 94/100\n",
            "102/102 [==============================] - 0s 976us/step - loss: 0.4407 - accuracy: 0.7910\n",
            "Epoch 95/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.7929\n",
            "Epoch 96/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7886\n",
            "Epoch 97/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4417 - accuracy: 0.7935\n",
            "Epoch 98/100\n",
            "102/102 [==============================] - 0s 974us/step - loss: 0.4411 - accuracy: 0.7935\n",
            "Epoch 99/100\n",
            "102/102 [==============================] - 0s 942us/step - loss: 0.4399 - accuracy: 0.7877\n",
            "Epoch 100/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7898\n",
            "26/26 [==============================] - 0s 914us/step - loss: 0.4931 - accuracy: 0.7521\n",
            "[0.49308356642723083, 0.7521472573280334]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.83      0.77       408\n",
            "           1       0.80      0.68      0.73       407\n",
            "\n",
            "    accuracy                           0.75       815\n",
            "   macro avg       0.76      0.75      0.75       815\n",
            "weighted avg       0.76      0.75      0.75       815\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h4N2vi1s74I"
      },
      "source": [
        "METHOD2:Oversampling minority class by duplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMOdKKmZ-hNj"
      },
      "source": [
        "\n",
        "# Class count\n",
        "count_class_0, count_class_1 = final.Exited.value_counts()\n",
        "\n",
        "# Divide by class\n",
        "final_class_0 = final[final['Exited'] == 0]\n",
        "final_class_1 = final[final['Exited'] == 1]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu4H6HwhtQPW",
        "outputId": "1018d702-cb91-44e0-a247-59bfc87d3366"
      },
      "source": [
        "# Oversample 1-class and concat the DataFrames of both class\n",
        "final_class_1_over = final_class_1.sample(count_class_0,replace=True)\n",
        "final_test_over = pd.concat([final_class_0, final_class_1_over], axis=0)\n",
        "print('Random over-sampling:')\n",
        "print(final_test_over.Exited.value_counts())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random over-sampling:\n",
            "1    7963\n",
            "0    7963\n",
            "Name: Exited, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VJT9JAZtnyb"
      },
      "source": [
        "X = final_test_over.drop('Exited',axis='columns')\n",
        "y = final_test_over['Exited']\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JbkHjw9vFd7",
        "outputId": "8133aa0a-0020-470d-cfa9-098e79b1bc83"
      },
      "source": [
        "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "399/399 [==============================] - 1s 1ms/step - loss: 0.6430 - accuracy: 0.6359\n",
            "Epoch 2/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.5936 - accuracy: 0.6848\n",
            "Epoch 3/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.5557 - accuracy: 0.7197\n",
            "Epoch 4/100\n",
            "399/399 [==============================] - 0s 975us/step - loss: 0.5183 - accuracy: 0.7495\n",
            "Epoch 5/100\n",
            "399/399 [==============================] - 0s 983us/step - loss: 0.4957 - accuracy: 0.7589\n",
            "Epoch 6/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7651\n",
            "Epoch 7/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7635\n",
            "Epoch 8/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7650\n",
            "Epoch 9/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7701\n",
            "Epoch 10/100\n",
            "399/399 [==============================] - 0s 963us/step - loss: 0.4682 - accuracy: 0.7706\n",
            "Epoch 11/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7700\n",
            "Epoch 12/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7750\n",
            "Epoch 13/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7712\n",
            "Epoch 14/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7744\n",
            "Epoch 15/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4580 - accuracy: 0.7750\n",
            "Epoch 16/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.7761\n",
            "Epoch 17/100\n",
            "399/399 [==============================] - 0s 978us/step - loss: 0.4552 - accuracy: 0.7772\n",
            "Epoch 18/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.7787\n",
            "Epoch 19/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7797\n",
            "Epoch 20/100\n",
            "399/399 [==============================] - 0s 988us/step - loss: 0.4524 - accuracy: 0.7802\n",
            "Epoch 21/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.7794\n",
            "Epoch 22/100\n",
            "399/399 [==============================] - 0s 989us/step - loss: 0.4502 - accuracy: 0.7814\n",
            "Epoch 23/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7838\n",
            "Epoch 24/100\n",
            "399/399 [==============================] - 0s 996us/step - loss: 0.4480 - accuracy: 0.7844\n",
            "Epoch 25/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.7849\n",
            "Epoch 26/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.7832\n",
            "Epoch 27/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.7837\n",
            "Epoch 28/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7859\n",
            "Epoch 29/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.7859\n",
            "Epoch 30/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7867\n",
            "Epoch 31/100\n",
            "399/399 [==============================] - 0s 986us/step - loss: 0.4435 - accuracy: 0.7867\n",
            "Epoch 32/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4415 - accuracy: 0.7877\n",
            "Epoch 33/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7893\n",
            "Epoch 34/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.7883\n",
            "Epoch 35/100\n",
            "399/399 [==============================] - 0s 995us/step - loss: 0.4410 - accuracy: 0.7888\n",
            "Epoch 36/100\n",
            "399/399 [==============================] - 0s 965us/step - loss: 0.4403 - accuracy: 0.7889\n",
            "Epoch 37/100\n",
            "399/399 [==============================] - 0s 979us/step - loss: 0.4395 - accuracy: 0.7885\n",
            "Epoch 38/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.7898\n",
            "Epoch 39/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4379 - accuracy: 0.7918\n",
            "Epoch 40/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.7916\n",
            "Epoch 41/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.7942\n",
            "Epoch 42/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.7924\n",
            "Epoch 43/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.7918\n",
            "Epoch 44/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4362 - accuracy: 0.7920\n",
            "Epoch 45/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.7947\n",
            "Epoch 46/100\n",
            "399/399 [==============================] - 0s 959us/step - loss: 0.4356 - accuracy: 0.7939\n",
            "Epoch 47/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.7954\n",
            "Epoch 48/100\n",
            "399/399 [==============================] - 0s 970us/step - loss: 0.4342 - accuracy: 0.7935\n",
            "Epoch 49/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.7973\n",
            "Epoch 50/100\n",
            "399/399 [==============================] - 0s 999us/step - loss: 0.4333 - accuracy: 0.7969\n",
            "Epoch 51/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.7961\n",
            "Epoch 52/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.7954\n",
            "Epoch 53/100\n",
            "399/399 [==============================] - 0s 973us/step - loss: 0.4316 - accuracy: 0.7963\n",
            "Epoch 54/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4326 - accuracy: 0.7954\n",
            "Epoch 55/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.7948\n",
            "Epoch 56/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4306 - accuracy: 0.7964\n",
            "Epoch 57/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.7981\n",
            "Epoch 58/100\n",
            "399/399 [==============================] - 0s 975us/step - loss: 0.4298 - accuracy: 0.7983\n",
            "Epoch 59/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.7981\n",
            "Epoch 60/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.7988\n",
            "Epoch 61/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.7981\n",
            "Epoch 62/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.7993\n",
            "Epoch 63/100\n",
            "399/399 [==============================] - 0s 980us/step - loss: 0.4283 - accuracy: 0.7971\n",
            "Epoch 64/100\n",
            "399/399 [==============================] - 0s 998us/step - loss: 0.4265 - accuracy: 0.7951\n",
            "Epoch 65/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4266 - accuracy: 0.8015\n",
            "Epoch 66/100\n",
            "399/399 [==============================] - 0s 997us/step - loss: 0.4252 - accuracy: 0.8005\n",
            "Epoch 67/100\n",
            "399/399 [==============================] - 0s 987us/step - loss: 0.4255 - accuracy: 0.7982\n",
            "Epoch 68/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4254 - accuracy: 0.8013\n",
            "Epoch 69/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4252 - accuracy: 0.8005\n",
            "Epoch 70/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4223 - accuracy: 0.8009\n",
            "Epoch 71/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4230 - accuracy: 0.7999\n",
            "Epoch 72/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4241 - accuracy: 0.7988\n",
            "Epoch 73/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4226 - accuracy: 0.8020\n",
            "Epoch 74/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4222 - accuracy: 0.8019\n",
            "Epoch 75/100\n",
            "399/399 [==============================] - 0s 995us/step - loss: 0.4220 - accuracy: 0.8022\n",
            "Epoch 76/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4202 - accuracy: 0.8034\n",
            "Epoch 77/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4199 - accuracy: 0.8037\n",
            "Epoch 78/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4191 - accuracy: 0.8031\n",
            "Epoch 79/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4205 - accuracy: 0.8034\n",
            "Epoch 80/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4194 - accuracy: 0.8028\n",
            "Epoch 81/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4193 - accuracy: 0.8033\n",
            "Epoch 82/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4190 - accuracy: 0.8034\n",
            "Epoch 83/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.8061\n",
            "Epoch 84/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4182 - accuracy: 0.8043\n",
            "Epoch 85/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.8045\n",
            "Epoch 86/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4177 - accuracy: 0.8073\n",
            "Epoch 87/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4178 - accuracy: 0.8071\n",
            "Epoch 88/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4160 - accuracy: 0.8055\n",
            "Epoch 89/100\n",
            "399/399 [==============================] - 0s 998us/step - loss: 0.4164 - accuracy: 0.8085\n",
            "Epoch 90/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.8053\n",
            "Epoch 91/100\n",
            "399/399 [==============================] - 0s 978us/step - loss: 0.4157 - accuracy: 0.8075\n",
            "Epoch 92/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4158 - accuracy: 0.8028\n",
            "Epoch 93/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8077\n",
            "Epoch 94/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4152 - accuracy: 0.8062\n",
            "Epoch 95/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4138 - accuracy: 0.8088\n",
            "Epoch 96/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8083\n",
            "Epoch 97/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4140 - accuracy: 0.8062\n",
            "Epoch 98/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4123 - accuracy: 0.8113\n",
            "Epoch 99/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4125 - accuracy: 0.8100\n",
            "Epoch 100/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4121 - accuracy: 0.8093\n",
            "100/100 [==============================] - 0s 770us/step - loss: 0.4320 - accuracy: 0.7969\n",
            "[0.4319937825202942, 0.7969240546226501]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.77      0.79      1593\n",
            "           1       0.78      0.82      0.80      1593\n",
            "\n",
            "    accuracy                           0.80      3186\n",
            "   macro avg       0.80      0.80      0.80      3186\n",
            "weighted avg       0.80      0.80      0.80      3186\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9KyjAm5vrYe"
      },
      "source": [
        "METHOD3:SMOTE-->Synthetic minority oversampling technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52PcDDAivKon"
      },
      "source": [
        "X = final.drop('Exited',axis='columns')\n",
        "y = final['Exited']"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFcy8gV_w-bx",
        "outputId": "864cb23d-f271-4b57-e3a7-1e75bfec2d2b"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(sampling_strategy='minority')\n",
        "X_sm, y_sm = smote.fit_sample(X, y)\n",
        "\n",
        "#y_sm.value_counts()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkGlf6OLxWQ3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=15, stratify=y_sm)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-g5cpJuxegR",
        "outputId": "5286d840-36f5-4adc-abf3-a5ca9ec682d0"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12740,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CbHi11uxkw1",
        "outputId": "9deab406-3cb0-4ffd-986d-d6d28fbec464"
      },
      "source": [
        "\n",
        "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "399/399 [==============================] - 1s 970us/step - loss: 0.6509 - accuracy: 0.6200\n",
            "Epoch 2/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.5942 - accuracy: 0.6901\n",
            "Epoch 3/100\n",
            "399/399 [==============================] - 0s 990us/step - loss: 0.5573 - accuracy: 0.7217\n",
            "Epoch 4/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.5271 - accuracy: 0.7464\n",
            "Epoch 5/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7604\n",
            "Epoch 6/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7723\n",
            "Epoch 7/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.7727\n",
            "Epoch 8/100\n",
            "399/399 [==============================] - 0s 975us/step - loss: 0.4660 - accuracy: 0.7765\n",
            "Epoch 9/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7783\n",
            "Epoch 10/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7766\n",
            "Epoch 11/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.7780\n",
            "Epoch 12/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7791\n",
            "Epoch 13/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.7838\n",
            "Epoch 14/100\n",
            "399/399 [==============================] - 0s 977us/step - loss: 0.4491 - accuracy: 0.7817\n",
            "Epoch 15/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7807\n",
            "Epoch 16/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.7821\n",
            "Epoch 17/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7846\n",
            "Epoch 18/100\n",
            "399/399 [==============================] - 0s 989us/step - loss: 0.4441 - accuracy: 0.7836\n",
            "Epoch 19/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4431 - accuracy: 0.7874\n",
            "Epoch 20/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7860\n",
            "Epoch 21/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7886\n",
            "Epoch 22/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.7894\n",
            "Epoch 23/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.7893\n",
            "Epoch 24/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4388 - accuracy: 0.7898\n",
            "Epoch 25/100\n",
            "399/399 [==============================] - 0s 998us/step - loss: 0.4385 - accuracy: 0.7899\n",
            "Epoch 26/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.7927\n",
            "Epoch 27/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.7941\n",
            "Epoch 28/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.7927\n",
            "Epoch 29/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.7946\n",
            "Epoch 30/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4337 - accuracy: 0.7938\n",
            "Epoch 31/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4326 - accuracy: 0.7939\n",
            "Epoch 32/100\n",
            "399/399 [==============================] - 0s 982us/step - loss: 0.4320 - accuracy: 0.7952\n",
            "Epoch 33/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.7957\n",
            "Epoch 34/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.7969\n",
            "Epoch 35/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4304 - accuracy: 0.7991\n",
            "Epoch 36/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.7962\n",
            "Epoch 37/100\n",
            "399/399 [==============================] - 0s 969us/step - loss: 0.4291 - accuracy: 0.7972\n",
            "Epoch 38/100\n",
            "399/399 [==============================] - 0s 982us/step - loss: 0.4273 - accuracy: 0.8000\n",
            "Epoch 39/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4263 - accuracy: 0.7998\n",
            "Epoch 40/100\n",
            "399/399 [==============================] - 0s 995us/step - loss: 0.4261 - accuracy: 0.8000\n",
            "Epoch 41/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4254 - accuracy: 0.8008\n",
            "Epoch 42/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.8016\n",
            "Epoch 43/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4243 - accuracy: 0.7991\n",
            "Epoch 44/100\n",
            "399/399 [==============================] - 0s 975us/step - loss: 0.4239 - accuracy: 0.8019\n",
            "Epoch 45/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4240 - accuracy: 0.8004\n",
            "Epoch 46/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4247 - accuracy: 0.7971\n",
            "Epoch 47/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4211 - accuracy: 0.8037\n",
            "Epoch 48/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4229 - accuracy: 0.8024\n",
            "Epoch 49/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4224 - accuracy: 0.8034\n",
            "Epoch 50/100\n",
            "399/399 [==============================] - 0s 999us/step - loss: 0.4216 - accuracy: 0.8007\n",
            "Epoch 51/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4224 - accuracy: 0.8002\n",
            "Epoch 52/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4197 - accuracy: 0.8043\n",
            "Epoch 53/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4200 - accuracy: 0.8046\n",
            "Epoch 54/100\n",
            "399/399 [==============================] - 0s 957us/step - loss: 0.4197 - accuracy: 0.8030\n",
            "Epoch 55/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4199 - accuracy: 0.8036\n",
            "Epoch 56/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4182 - accuracy: 0.8042\n",
            "Epoch 57/100\n",
            "399/399 [==============================] - 0s 985us/step - loss: 0.4162 - accuracy: 0.8043\n",
            "Epoch 58/100\n",
            "399/399 [==============================] - 0s 1000us/step - loss: 0.4180 - accuracy: 0.8060\n",
            "Epoch 59/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4176 - accuracy: 0.8060\n",
            "Epoch 60/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4174 - accuracy: 0.8073\n",
            "Epoch 61/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4167 - accuracy: 0.8044\n",
            "Epoch 62/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4166 - accuracy: 0.8048\n",
            "Epoch 63/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4155 - accuracy: 0.8078\n",
            "Epoch 64/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4168 - accuracy: 0.8056\n",
            "Epoch 65/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4162 - accuracy: 0.8052\n",
            "Epoch 66/100\n",
            "399/399 [==============================] - 0s 992us/step - loss: 0.4152 - accuracy: 0.8105\n",
            "Epoch 67/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4143 - accuracy: 0.8058\n",
            "Epoch 68/100\n",
            "399/399 [==============================] - 0s 978us/step - loss: 0.4132 - accuracy: 0.8062\n",
            "Epoch 69/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8071\n",
            "Epoch 70/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4152 - accuracy: 0.8058\n",
            "Epoch 71/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4128 - accuracy: 0.8096\n",
            "Epoch 72/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4113 - accuracy: 0.8074\n",
            "Epoch 73/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4113 - accuracy: 0.8103\n",
            "Epoch 74/100\n",
            "399/399 [==============================] - 0s 977us/step - loss: 0.4127 - accuracy: 0.8097\n",
            "Epoch 75/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4106 - accuracy: 0.8084\n",
            "Epoch 76/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4125 - accuracy: 0.8071\n",
            "Epoch 77/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4102 - accuracy: 0.8097\n",
            "Epoch 78/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4101 - accuracy: 0.8101\n",
            "Epoch 79/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4104 - accuracy: 0.8087\n",
            "Epoch 80/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4095 - accuracy: 0.8104\n",
            "Epoch 81/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4091 - accuracy: 0.8119\n",
            "Epoch 82/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.8119\n",
            "Epoch 83/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4088 - accuracy: 0.8121\n",
            "Epoch 84/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.8108\n",
            "Epoch 85/100\n",
            "399/399 [==============================] - 0s 994us/step - loss: 0.4068 - accuracy: 0.8109\n",
            "Epoch 86/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4073 - accuracy: 0.8112\n",
            "Epoch 87/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4065 - accuracy: 0.8128\n",
            "Epoch 88/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4069 - accuracy: 0.8108\n",
            "Epoch 89/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4051 - accuracy: 0.8128\n",
            "Epoch 90/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4071 - accuracy: 0.8104\n",
            "Epoch 91/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4052 - accuracy: 0.8137\n",
            "Epoch 92/100\n",
            "399/399 [==============================] - 0s 990us/step - loss: 0.4034 - accuracy: 0.8129\n",
            "Epoch 93/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4055 - accuracy: 0.8126\n",
            "Epoch 94/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4045 - accuracy: 0.8144\n",
            "Epoch 95/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4039 - accuracy: 0.8167\n",
            "Epoch 96/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4038 - accuracy: 0.8133\n",
            "Epoch 97/100\n",
            "399/399 [==============================] - 0s 971us/step - loss: 0.4041 - accuracy: 0.8133\n",
            "Epoch 98/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4034 - accuracy: 0.8130\n",
            "Epoch 99/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4038 - accuracy: 0.8130\n",
            "Epoch 100/100\n",
            "399/399 [==============================] - 0s 1ms/step - loss: 0.4029 - accuracy: 0.8136\n",
            "100/100 [==============================] - 0s 762us/step - loss: 0.4064 - accuracy: 0.8114\n",
            "[0.4063519239425659, 0.8113622069358826]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.80      0.81      1593\n",
            "           1       0.81      0.82      0.81      1593\n",
            "\n",
            "    accuracy                           0.81      3186\n",
            "   macro avg       0.81      0.81      0.81      3186\n",
            "weighted avg       0.81      0.81      0.81      3186\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWf_RQIEzq7K"
      },
      "source": [
        "METHOD4:Ensemble with undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cDxY8JWzD4t"
      },
      "source": [
        "# Regain Original features and labels\n",
        "X = final.drop('Exited',axis='columns')\n",
        "y = final['Exited']"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LCJsXsi0HmV"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol6Wtcro0Lc2",
        "outputId": "615e955a-20bf-4f23-a559-8d07e2be5570"
      },
      "source": [
        "y_train.value_counts()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6370\n",
              "1    1630\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pALN5AV0Tkj"
      },
      "source": [
        "model1 --> class1(1630) + class0(0, 1630)\n",
        "\n",
        "model2 --> class1(1630) + class0(1630, 3260)\n",
        "\n",
        "model3 --> class1(1630) + class0(3260, 4890)\n",
        "\n",
        "model4 --> class1(1630) + class0(4890,6370)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7HXa9MV0PyW"
      },
      "source": [
        "df3 = X_train.copy()\n",
        "df3['Exited'] = y_train"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "tEHZXQ4q1Oni",
        "outputId": "87b0cd50-1422-48d0-966d-53bb51006bda"
      },
      "source": [
        "df3.head(5)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>France</th>\n",
              "      <th>Germany</th>\n",
              "      <th>Spain</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5710</th>\n",
              "      <td>0.856</td>\n",
              "      <td>0</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.554265</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.339721</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3745</th>\n",
              "      <td>0.852</td>\n",
              "      <td>1</td>\n",
              "      <td>0.256757</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.371163</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.980432</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5429</th>\n",
              "      <td>0.664</td>\n",
              "      <td>1</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.325318</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>551</th>\n",
              "      <td>0.648</td>\n",
              "      <td>0</td>\n",
              "      <td>0.391892</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.426077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.010339</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8967</th>\n",
              "      <td>0.970</td>\n",
              "      <td>0</td>\n",
              "      <td>0.094595</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.417230</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CreditScore  Gender       Age  Tenure  ...  France  Germany  Spain  Exited\n",
              "5710        0.856       0  0.216216     0.5  ...       1        0      0       0\n",
              "3745        0.852       1  0.256757     0.1  ...       0        1      0       0\n",
              "5429        0.664       1  0.405405     0.7  ...       1        0      0       0\n",
              "551         0.648       0  0.391892     0.6  ...       0        1      0       1\n",
              "8967        0.970       0  0.094595     0.7  ...       1        0      0       0\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01p706r_1WVM"
      },
      "source": [
        "df3_class0 = df3[df3.Exited==0]\n",
        "df3_class1 = df3[df3.Exited==1]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3em7NsFy1icp"
      },
      "source": [
        "def get_train_batch(df_majority, df_minority, start, end):\n",
        "    df_train = pd.concat([df_majority[start:end], df_minority], axis=0)\n",
        "\n",
        "    X_train = df_train.drop('Exited', axis='columns')\n",
        "    y_train = df_train.Exited\n",
        "    return X_train, y_train"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGq7A1eW1ubp",
        "outputId": "e6a22a46-d6d0-4957-c2ea-a3857f161a16"
      },
      "source": [
        "X_train, y_train = get_train_batch(df3_class0, df3_class1, 0, 1630)\n",
        "\n",
        "y_pred1 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5405\n",
            "Epoch 2/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.6605 - accuracy: 0.6113\n",
            "Epoch 3/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.6335 - accuracy: 0.6540\n",
            "Epoch 4/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.6188 - accuracy: 0.6712\n",
            "Epoch 5/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.6084 - accuracy: 0.6798\n",
            "Epoch 6/100\n",
            "102/102 [==============================] - 0s 991us/step - loss: 0.5987 - accuracy: 0.6896\n",
            "Epoch 7/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5880 - accuracy: 0.6991\n",
            "Epoch 8/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.6975\n",
            "Epoch 9/100\n",
            "102/102 [==============================] - 0s 974us/step - loss: 0.5696 - accuracy: 0.7098\n",
            "Epoch 10/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5607 - accuracy: 0.7196\n",
            "Epoch 11/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.7255\n",
            "Epoch 12/100\n",
            "102/102 [==============================] - 0s 939us/step - loss: 0.5452 - accuracy: 0.7362\n",
            "Epoch 13/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5346 - accuracy: 0.7387\n",
            "Epoch 14/100\n",
            "102/102 [==============================] - 0s 985us/step - loss: 0.5258 - accuracy: 0.7466\n",
            "Epoch 15/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5181 - accuracy: 0.7488\n",
            "Epoch 16/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7537\n",
            "Epoch 17/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.7549\n",
            "Epoch 18/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.7571\n",
            "Epoch 19/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7613\n",
            "Epoch 20/100\n",
            "102/102 [==============================] - 0s 991us/step - loss: 0.4930 - accuracy: 0.7574\n",
            "Epoch 21/100\n",
            "102/102 [==============================] - 0s 932us/step - loss: 0.4930 - accuracy: 0.7531\n",
            "Epoch 22/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.7635\n",
            "Epoch 23/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.7663\n",
            "Epoch 24/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7641\n",
            "Epoch 25/100\n",
            "102/102 [==============================] - 0s 988us/step - loss: 0.4814 - accuracy: 0.7702\n",
            "Epoch 26/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.7669\n",
            "Epoch 27/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.7687\n",
            "Epoch 28/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.7675\n",
            "Epoch 29/100\n",
            "102/102 [==============================] - 0s 959us/step - loss: 0.4734 - accuracy: 0.7718\n",
            "Epoch 30/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7739\n",
            "Epoch 31/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.7672\n",
            "Epoch 32/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.7669\n",
            "Epoch 33/100\n",
            "102/102 [==============================] - 0s 992us/step - loss: 0.4708 - accuracy: 0.7706\n",
            "Epoch 34/100\n",
            "102/102 [==============================] - 0s 940us/step - loss: 0.4701 - accuracy: 0.7733\n",
            "Epoch 35/100\n",
            "102/102 [==============================] - 0s 976us/step - loss: 0.4684 - accuracy: 0.7687\n",
            "Epoch 36/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7730\n",
            "Epoch 37/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.7715\n",
            "Epoch 38/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7764\n",
            "Epoch 39/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7733\n",
            "Epoch 40/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7758\n",
            "Epoch 41/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7696\n",
            "Epoch 42/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7776\n",
            "Epoch 43/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7761\n",
            "Epoch 44/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7773\n",
            "Epoch 45/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7742\n",
            "Epoch 46/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4658 - accuracy: 0.7693\n",
            "Epoch 47/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7742\n",
            "Epoch 48/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7736\n",
            "Epoch 49/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7718\n",
            "Epoch 50/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7804\n",
            "Epoch 51/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7798\n",
            "Epoch 52/100\n",
            "102/102 [==============================] - 0s 965us/step - loss: 0.4573 - accuracy: 0.7773\n",
            "Epoch 53/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7712\n",
            "Epoch 54/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.7782\n",
            "Epoch 55/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.7794\n",
            "Epoch 56/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.7813\n",
            "Epoch 57/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.7773\n",
            "Epoch 58/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.7745\n",
            "Epoch 59/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.7721\n",
            "Epoch 60/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.7788\n",
            "Epoch 61/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.7850\n",
            "Epoch 62/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.7834\n",
            "Epoch 63/100\n",
            "102/102 [==============================] - 0s 993us/step - loss: 0.4525 - accuracy: 0.7816\n",
            "Epoch 64/100\n",
            "102/102 [==============================] - 0s 979us/step - loss: 0.4517 - accuracy: 0.7791\n",
            "Epoch 65/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7813\n",
            "Epoch 66/100\n",
            "102/102 [==============================] - 0s 972us/step - loss: 0.4519 - accuracy: 0.7819\n",
            "Epoch 67/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.7770\n",
            "Epoch 68/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.7828\n",
            "Epoch 69/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.7831\n",
            "Epoch 70/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.7837\n",
            "Epoch 71/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7794\n",
            "Epoch 72/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7868\n",
            "Epoch 73/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7840\n",
            "Epoch 74/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7804\n",
            "Epoch 75/100\n",
            "102/102 [==============================] - 0s 985us/step - loss: 0.4475 - accuracy: 0.7831\n",
            "Epoch 76/100\n",
            "102/102 [==============================] - 0s 976us/step - loss: 0.4452 - accuracy: 0.7874\n",
            "Epoch 77/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.7923\n",
            "Epoch 78/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7923\n",
            "Epoch 79/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7856\n",
            "Epoch 80/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7877\n",
            "Epoch 81/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.7853\n",
            "Epoch 82/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.7887\n",
            "Epoch 83/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.7840\n",
            "Epoch 84/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7828\n",
            "Epoch 85/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.7893\n",
            "Epoch 86/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.7865\n",
            "Epoch 87/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7890\n",
            "Epoch 88/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.7883\n",
            "Epoch 89/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.7899\n",
            "Epoch 90/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.7899\n",
            "Epoch 91/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4415 - accuracy: 0.7883\n",
            "Epoch 92/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.7917\n",
            "Epoch 93/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.7893\n",
            "Epoch 94/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.7871\n",
            "Epoch 95/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.7936\n",
            "Epoch 96/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.7917\n",
            "Epoch 97/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7899\n",
            "Epoch 98/100\n",
            "102/102 [==============================] - 0s 991us/step - loss: 0.4400 - accuracy: 0.7908\n",
            "Epoch 99/100\n",
            "102/102 [==============================] - 0s 971us/step - loss: 0.4370 - accuracy: 0.7911\n",
            "Epoch 100/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.7890\n",
            "63/63 [==============================] - 0s 977us/step - loss: 0.4580 - accuracy: 0.7875\n",
            "[0.45797136425971985, 0.7875000238418579]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.80      0.86      1593\n",
            "           1       0.49      0.75      0.59       407\n",
            "\n",
            "    accuracy                           0.79      2000\n",
            "   macro avg       0.71      0.78      0.72      2000\n",
            "weighted avg       0.84      0.79      0.80      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrcQOsSV12Ou",
        "outputId": "636472a5-99e3-42e4-c52e-fdd69415f8f1"
      },
      "source": [
        "X_train, y_train = get_train_batch(df3_class0, df3_class1, 1630, 3260)\n",
        "\n",
        "y_pred2 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "102/102 [==============================] - 0s 980us/step - loss: 0.6836 - accuracy: 0.5574\n",
            "Epoch 2/100\n",
            "102/102 [==============================] - 0s 994us/step - loss: 0.6455 - accuracy: 0.6298\n",
            "Epoch 3/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.6227 - accuracy: 0.6521\n",
            "Epoch 4/100\n",
            "102/102 [==============================] - 0s 955us/step - loss: 0.6068 - accuracy: 0.6798\n",
            "Epoch 5/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5952 - accuracy: 0.6828\n",
            "Epoch 6/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5860 - accuracy: 0.6917\n",
            "Epoch 7/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5802 - accuracy: 0.6914\n",
            "Epoch 8/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5748 - accuracy: 0.6951\n",
            "Epoch 9/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5713 - accuracy: 0.6988\n",
            "Epoch 10/100\n",
            "102/102 [==============================] - 0s 983us/step - loss: 0.5681 - accuracy: 0.7037\n",
            "Epoch 11/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5641 - accuracy: 0.7058\n",
            "Epoch 12/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5584 - accuracy: 0.7129\n",
            "Epoch 13/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5543 - accuracy: 0.7169\n",
            "Epoch 14/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5472 - accuracy: 0.7248\n",
            "Epoch 15/100\n",
            "102/102 [==============================] - 0s 989us/step - loss: 0.5389 - accuracy: 0.7304\n",
            "Epoch 16/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5283 - accuracy: 0.7368\n",
            "Epoch 17/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.7475\n",
            "Epoch 18/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5113 - accuracy: 0.7503\n",
            "Epoch 19/100\n",
            "102/102 [==============================] - 0s 940us/step - loss: 0.5027 - accuracy: 0.7577\n",
            "Epoch 20/100\n",
            "102/102 [==============================] - 0s 905us/step - loss: 0.4977 - accuracy: 0.7635\n",
            "Epoch 21/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7663\n",
            "Epoch 22/100\n",
            "102/102 [==============================] - 0s 973us/step - loss: 0.4901 - accuracy: 0.7675\n",
            "Epoch 23/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.7699\n",
            "Epoch 24/100\n",
            "102/102 [==============================] - 0s 914us/step - loss: 0.4838 - accuracy: 0.7687\n",
            "Epoch 25/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.7724\n",
            "Epoch 26/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7709\n",
            "Epoch 27/100\n",
            "102/102 [==============================] - 0s 971us/step - loss: 0.4774 - accuracy: 0.7678\n",
            "Epoch 28/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4763 - accuracy: 0.7702\n",
            "Epoch 29/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.7739\n",
            "Epoch 30/100\n",
            "102/102 [==============================] - 0s 953us/step - loss: 0.4710 - accuracy: 0.7742\n",
            "Epoch 31/100\n",
            "102/102 [==============================] - 0s 981us/step - loss: 0.4697 - accuracy: 0.7727\n",
            "Epoch 32/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4708 - accuracy: 0.7696\n",
            "Epoch 33/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7733\n",
            "Epoch 34/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7748\n",
            "Epoch 35/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.7727\n",
            "Epoch 36/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7755\n",
            "Epoch 37/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7755\n",
            "Epoch 38/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7776\n",
            "Epoch 39/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7736\n",
            "Epoch 40/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7758\n",
            "Epoch 41/100\n",
            "102/102 [==============================] - 0s 991us/step - loss: 0.4649 - accuracy: 0.7770\n",
            "Epoch 42/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7733\n",
            "Epoch 43/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7773\n",
            "Epoch 44/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7761\n",
            "Epoch 45/100\n",
            "102/102 [==============================] - 0s 982us/step - loss: 0.4619 - accuracy: 0.7764\n",
            "Epoch 46/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7770\n",
            "Epoch 47/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.7758\n",
            "Epoch 48/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7764\n",
            "Epoch 49/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7758\n",
            "Epoch 50/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4580 - accuracy: 0.7791\n",
            "Epoch 51/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7825\n",
            "Epoch 52/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4570 - accuracy: 0.7776\n",
            "Epoch 53/100\n",
            "102/102 [==============================] - 0s 909us/step - loss: 0.4578 - accuracy: 0.7764\n",
            "Epoch 54/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7773\n",
            "Epoch 55/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.7825\n",
            "Epoch 56/100\n",
            "102/102 [==============================] - 0s 950us/step - loss: 0.4569 - accuracy: 0.7816\n",
            "Epoch 57/100\n",
            "102/102 [==============================] - 0s 922us/step - loss: 0.4560 - accuracy: 0.7822\n",
            "Epoch 58/100\n",
            "102/102 [==============================] - 0s 960us/step - loss: 0.4590 - accuracy: 0.7776\n",
            "Epoch 59/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.7807\n",
            "Epoch 60/100\n",
            "102/102 [==============================] - 0s 973us/step - loss: 0.4548 - accuracy: 0.7810\n",
            "Epoch 61/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.7804\n",
            "Epoch 62/100\n",
            "102/102 [==============================] - 0s 942us/step - loss: 0.4553 - accuracy: 0.7791\n",
            "Epoch 63/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.7825\n",
            "Epoch 64/100\n",
            "102/102 [==============================] - 0s 967us/step - loss: 0.4543 - accuracy: 0.7819\n",
            "Epoch 65/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.7837\n",
            "Epoch 66/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.7837\n",
            "Epoch 67/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.7813\n",
            "Epoch 68/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.7825\n",
            "Epoch 69/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7847\n",
            "Epoch 70/100\n",
            "102/102 [==============================] - 0s 965us/step - loss: 0.4528 - accuracy: 0.7798\n",
            "Epoch 71/100\n",
            "102/102 [==============================] - 0s 927us/step - loss: 0.4522 - accuracy: 0.7816\n",
            "Epoch 72/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.7801\n",
            "Epoch 73/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7902\n",
            "Epoch 74/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.7831\n",
            "Epoch 75/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.7828\n",
            "Epoch 76/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7868\n",
            "Epoch 77/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7819\n",
            "Epoch 78/100\n",
            "102/102 [==============================] - 0s 984us/step - loss: 0.4518 - accuracy: 0.7844\n",
            "Epoch 79/100\n",
            "102/102 [==============================] - 0s 952us/step - loss: 0.4532 - accuracy: 0.7785\n",
            "Epoch 80/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7819\n",
            "Epoch 81/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7847\n",
            "Epoch 82/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.7865\n",
            "Epoch 83/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.7868\n",
            "Epoch 84/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.7828\n",
            "Epoch 85/100\n",
            "102/102 [==============================] - 0s 993us/step - loss: 0.4500 - accuracy: 0.7837\n",
            "Epoch 86/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.7877\n",
            "Epoch 87/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7847\n",
            "Epoch 88/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7859\n",
            "Epoch 89/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7871\n",
            "Epoch 90/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.7905\n",
            "Epoch 91/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7868\n",
            "Epoch 92/100\n",
            "102/102 [==============================] - 0s 986us/step - loss: 0.4486 - accuracy: 0.7794\n",
            "Epoch 93/100\n",
            "102/102 [==============================] - 0s 939us/step - loss: 0.4478 - accuracy: 0.7911\n",
            "Epoch 94/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.7883\n",
            "Epoch 95/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7905\n",
            "Epoch 96/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.7923\n",
            "Epoch 97/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7862\n",
            "Epoch 98/100\n",
            "102/102 [==============================] - 0s 980us/step - loss: 0.4449 - accuracy: 0.7877\n",
            "Epoch 99/100\n",
            "102/102 [==============================] - 0s 978us/step - loss: 0.4458 - accuracy: 0.7853\n",
            "Epoch 100/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7902\n",
            "63/63 [==============================] - 0s 730us/step - loss: 0.4686 - accuracy: 0.7780\n",
            "[0.46855881810188293, 0.777999997138977]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.79      0.85      1593\n",
            "           1       0.47      0.75      0.58       407\n",
            "\n",
            "    accuracy                           0.78      2000\n",
            "   macro avg       0.70      0.77      0.71      2000\n",
            "weighted avg       0.83      0.78      0.79      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARbbutVF1901",
        "outputId": "139051dc-90db-4341-e592-0892b0648433"
      },
      "source": [
        "X_train, y_train = get_train_batch(df3_class0, df3_class1, 3260, 4890)\n",
        "\n",
        "y_pred3 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "102/102 [==============================] - 1s 1ms/step - loss: 0.6818 - accuracy: 0.5712\n",
            "Epoch 2/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.6398 - accuracy: 0.6509\n",
            "Epoch 3/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.6153 - accuracy: 0.6647\n",
            "Epoch 4/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.6008 - accuracy: 0.6779\n",
            "Epoch 5/100\n",
            "102/102 [==============================] - 0s 940us/step - loss: 0.5896 - accuracy: 0.6887\n",
            "Epoch 6/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5793 - accuracy: 0.7006\n",
            "Epoch 7/100\n",
            "102/102 [==============================] - 0s 981us/step - loss: 0.5711 - accuracy: 0.7132\n",
            "Epoch 8/100\n",
            "102/102 [==============================] - 0s 964us/step - loss: 0.5580 - accuracy: 0.7209\n",
            "Epoch 9/100\n",
            "102/102 [==============================] - 0s 983us/step - loss: 0.5494 - accuracy: 0.7230\n",
            "Epoch 10/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5403 - accuracy: 0.7371\n",
            "Epoch 11/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5305 - accuracy: 0.7439\n",
            "Epoch 12/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5233 - accuracy: 0.7460\n",
            "Epoch 13/100\n",
            "102/102 [==============================] - 0s 969us/step - loss: 0.5146 - accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.7583\n",
            "Epoch 15/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.5009 - accuracy: 0.7561\n",
            "Epoch 16/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7620\n",
            "Epoch 17/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.7644\n",
            "Epoch 18/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.7620\n",
            "Epoch 19/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.7693\n",
            "Epoch 20/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7693\n",
            "Epoch 21/100\n",
            "102/102 [==============================] - 0s 968us/step - loss: 0.4777 - accuracy: 0.7675\n",
            "Epoch 22/100\n",
            "102/102 [==============================] - 0s 977us/step - loss: 0.4757 - accuracy: 0.7675\n",
            "Epoch 23/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.7690\n",
            "Epoch 24/100\n",
            "102/102 [==============================] - 0s 970us/step - loss: 0.4744 - accuracy: 0.7647\n",
            "Epoch 25/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4710 - accuracy: 0.7702\n",
            "Epoch 26/100\n",
            "102/102 [==============================] - 0s 985us/step - loss: 0.4687 - accuracy: 0.7727\n",
            "Epoch 27/100\n",
            "102/102 [==============================] - 0s 948us/step - loss: 0.4673 - accuracy: 0.7718\n",
            "Epoch 28/100\n",
            "102/102 [==============================] - 0s 925us/step - loss: 0.4683 - accuracy: 0.7709\n",
            "Epoch 29/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7745\n",
            "Epoch 30/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7782\n",
            "Epoch 31/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7715\n",
            "Epoch 32/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7782\n",
            "Epoch 33/100\n",
            "102/102 [==============================] - 0s 966us/step - loss: 0.4623 - accuracy: 0.7770\n",
            "Epoch 34/100\n",
            "102/102 [==============================] - 0s 936us/step - loss: 0.4591 - accuracy: 0.7798\n",
            "Epoch 35/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7788\n",
            "Epoch 36/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7798\n",
            "Epoch 37/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.7798\n",
            "Epoch 38/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7807\n",
            "Epoch 39/100\n",
            "102/102 [==============================] - 0s 966us/step - loss: 0.4569 - accuracy: 0.7773\n",
            "Epoch 40/100\n",
            "102/102 [==============================] - 0s 974us/step - loss: 0.4543 - accuracy: 0.7828\n",
            "Epoch 41/100\n",
            "102/102 [==============================] - 0s 937us/step - loss: 0.4545 - accuracy: 0.7813\n",
            "Epoch 42/100\n",
            "102/102 [==============================] - 0s 926us/step - loss: 0.4534 - accuracy: 0.7804\n",
            "Epoch 43/100\n",
            "102/102 [==============================] - 0s 992us/step - loss: 0.4534 - accuracy: 0.7847\n",
            "Epoch 44/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.7850\n",
            "Epoch 45/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.7865\n",
            "Epoch 46/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7813\n",
            "Epoch 47/100\n",
            "102/102 [==============================] - 0s 973us/step - loss: 0.4504 - accuracy: 0.7810\n",
            "Epoch 48/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7868\n",
            "Epoch 49/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7807\n",
            "Epoch 50/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7813\n",
            "Epoch 51/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7856\n",
            "Epoch 52/100\n",
            "102/102 [==============================] - 0s 996us/step - loss: 0.4463 - accuracy: 0.7825\n",
            "Epoch 53/100\n",
            "102/102 [==============================] - 0s 981us/step - loss: 0.4458 - accuracy: 0.7856\n",
            "Epoch 54/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7856\n",
            "Epoch 55/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.7859\n",
            "Epoch 56/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.7874\n",
            "Epoch 57/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.7834\n",
            "Epoch 58/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.7880\n",
            "Epoch 59/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.7880\n",
            "Epoch 60/100\n",
            "102/102 [==============================] - 0s 940us/step - loss: 0.4452 - accuracy: 0.7856\n",
            "Epoch 61/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7933\n",
            "Epoch 62/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.7819\n",
            "Epoch 63/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.7929\n",
            "Epoch 64/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.7905\n",
            "Epoch 65/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.7911\n",
            "Epoch 66/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.7883\n",
            "Epoch 67/100\n",
            "102/102 [==============================] - 0s 964us/step - loss: 0.4399 - accuracy: 0.7923\n",
            "Epoch 68/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.7893\n",
            "Epoch 69/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.7883\n",
            "Epoch 70/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4351 - accuracy: 0.7966\n",
            "Epoch 71/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4389 - accuracy: 0.7899\n",
            "Epoch 72/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7933\n",
            "Epoch 73/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.7905\n",
            "Epoch 74/100\n",
            "102/102 [==============================] - 0s 976us/step - loss: 0.4355 - accuracy: 0.7923\n",
            "Epoch 75/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.7954\n",
            "Epoch 76/100\n",
            "102/102 [==============================] - 0s 971us/step - loss: 0.4364 - accuracy: 0.7920\n",
            "Epoch 77/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.7936\n",
            "Epoch 78/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.7979\n",
            "Epoch 79/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4330 - accuracy: 0.7966\n",
            "Epoch 80/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4325 - accuracy: 0.7951\n",
            "Epoch 81/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4332 - accuracy: 0.7945\n",
            "Epoch 82/100\n",
            "102/102 [==============================] - 0s 995us/step - loss: 0.4350 - accuracy: 0.7923\n",
            "Epoch 83/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4326 - accuracy: 0.7979\n",
            "Epoch 84/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.7963\n",
            "Epoch 85/100\n",
            "102/102 [==============================] - 0s 981us/step - loss: 0.4317 - accuracy: 0.7960\n",
            "Epoch 86/100\n",
            "102/102 [==============================] - 0s 934us/step - loss: 0.4312 - accuracy: 0.7994\n",
            "Epoch 87/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.7939\n",
            "Epoch 88/100\n",
            "102/102 [==============================] - 0s 954us/step - loss: 0.4324 - accuracy: 0.7929\n",
            "Epoch 89/100\n",
            "102/102 [==============================] - 0s 991us/step - loss: 0.4311 - accuracy: 0.7969\n",
            "Epoch 90/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4307 - accuracy: 0.7945\n",
            "Epoch 91/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.7929\n",
            "Epoch 92/100\n",
            "102/102 [==============================] - 0s 966us/step - loss: 0.4305 - accuracy: 0.7994\n",
            "Epoch 93/100\n",
            "102/102 [==============================] - 0s 965us/step - loss: 0.4323 - accuracy: 0.7972\n",
            "Epoch 94/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.7966\n",
            "Epoch 95/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4304 - accuracy: 0.7936\n",
            "Epoch 96/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4293 - accuracy: 0.7969\n",
            "Epoch 97/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.7997\n",
            "Epoch 98/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.7975\n",
            "Epoch 99/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.7997\n",
            "Epoch 100/100\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.7975\n",
            "63/63 [==============================] - 0s 712us/step - loss: 0.4449 - accuracy: 0.7870\n",
            "[0.4449111223220825, 0.7870000004768372]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.80      0.86      1593\n",
            "           1       0.48      0.73      0.58       407\n",
            "\n",
            "    accuracy                           0.79      2000\n",
            "   macro avg       0.70      0.77      0.72      2000\n",
            "weighted avg       0.83      0.79      0.80      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK_zFb7p2Jkb",
        "outputId": "8f62a1d7-64aa-4e2d-e056-c78688c26fd9"
      },
      "source": [
        "X_train, y_train = get_train_batch(df3_class0, df3_class1, 4890, 6370)\n",
        "\n",
        "y_pred4 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "98/98 [==============================] - 0s 988us/step - loss: 0.6973 - accuracy: 0.5315\n",
            "Epoch 2/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.6299\n",
            "Epoch 3/100\n",
            "98/98 [==============================] - 0s 962us/step - loss: 0.6280 - accuracy: 0.6518\n",
            "Epoch 4/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.6112 - accuracy: 0.6691\n",
            "Epoch 5/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.5985 - accuracy: 0.6807\n",
            "Epoch 6/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.5883 - accuracy: 0.6916\n",
            "Epoch 7/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.5788 - accuracy: 0.6987\n",
            "Epoch 8/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.5720 - accuracy: 0.7051\n",
            "Epoch 9/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.5653 - accuracy: 0.7048\n",
            "Epoch 10/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.5632 - accuracy: 0.7055\n",
            "Epoch 11/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.5559 - accuracy: 0.7212\n",
            "Epoch 12/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.5523 - accuracy: 0.7215\n",
            "Epoch 13/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.5469 - accuracy: 0.7241\n",
            "Epoch 14/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.5412 - accuracy: 0.7254\n",
            "Epoch 15/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.5373 - accuracy: 0.7328\n",
            "Epoch 16/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.5333 - accuracy: 0.7334\n",
            "Epoch 17/100\n",
            "98/98 [==============================] - 0s 956us/step - loss: 0.5272 - accuracy: 0.7347\n",
            "Epoch 18/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.7376\n",
            "Epoch 19/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.7408\n",
            "Epoch 20/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.7434\n",
            "Epoch 21/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.5087 - accuracy: 0.7518\n",
            "Epoch 22/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.7537\n",
            "Epoch 23/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.7511\n",
            "Epoch 24/100\n",
            "98/98 [==============================] - 0s 992us/step - loss: 0.4971 - accuracy: 0.7547\n",
            "Epoch 25/100\n",
            "98/98 [==============================] - 0s 963us/step - loss: 0.4962 - accuracy: 0.7547\n",
            "Epoch 26/100\n",
            "98/98 [==============================] - 0s 920us/step - loss: 0.4913 - accuracy: 0.7611\n",
            "Epoch 27/100\n",
            "98/98 [==============================] - 0s 989us/step - loss: 0.4872 - accuracy: 0.7662\n",
            "Epoch 28/100\n",
            "98/98 [==============================] - 0s 995us/step - loss: 0.4870 - accuracy: 0.7633\n",
            "Epoch 29/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7633\n",
            "Epoch 30/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7701\n",
            "Epoch 31/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7701\n",
            "Epoch 32/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.7675\n",
            "Epoch 33/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.7691\n",
            "Epoch 34/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4764 - accuracy: 0.7704\n",
            "Epoch 35/100\n",
            "98/98 [==============================] - 0s 958us/step - loss: 0.4734 - accuracy: 0.7682\n",
            "Epoch 36/100\n",
            "98/98 [==============================] - 0s 955us/step - loss: 0.4734 - accuracy: 0.7678\n",
            "Epoch 37/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.7695\n",
            "Epoch 38/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4720 - accuracy: 0.7704\n",
            "Epoch 39/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.7682\n",
            "Epoch 40/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.7685\n",
            "Epoch 41/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7733\n",
            "Epoch 42/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7688\n",
            "Epoch 43/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7746\n",
            "Epoch 44/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7707\n",
            "Epoch 45/100\n",
            "98/98 [==============================] - 0s 996us/step - loss: 0.4654 - accuracy: 0.7781\n",
            "Epoch 46/100\n",
            "98/98 [==============================] - 0s 982us/step - loss: 0.4654 - accuracy: 0.7733\n",
            "Epoch 47/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7727\n",
            "Epoch 48/100\n",
            "98/98 [==============================] - 0s 948us/step - loss: 0.4657 - accuracy: 0.7698\n",
            "Epoch 49/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7743\n",
            "Epoch 50/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7778\n",
            "Epoch 51/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7749\n",
            "Epoch 52/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7788\n",
            "Epoch 53/100\n",
            "98/98 [==============================] - 0s 963us/step - loss: 0.4606 - accuracy: 0.7743\n",
            "Epoch 54/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7756\n",
            "Epoch 55/100\n",
            "98/98 [==============================] - 0s 950us/step - loss: 0.4617 - accuracy: 0.7720\n",
            "Epoch 56/100\n",
            "98/98 [==============================] - 0s 941us/step - loss: 0.4590 - accuracy: 0.7791\n",
            "Epoch 57/100\n",
            "98/98 [==============================] - 0s 973us/step - loss: 0.4576 - accuracy: 0.7775\n",
            "Epoch 58/100\n",
            "98/98 [==============================] - 0s 981us/step - loss: 0.4571 - accuracy: 0.7820\n",
            "Epoch 59/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.7807\n",
            "Epoch 60/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7772\n",
            "Epoch 61/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.7788\n",
            "Epoch 62/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.7778\n",
            "Epoch 63/100\n",
            "98/98 [==============================] - 0s 990us/step - loss: 0.4551 - accuracy: 0.7814\n",
            "Epoch 64/100\n",
            "98/98 [==============================] - 0s 943us/step - loss: 0.4541 - accuracy: 0.7826\n",
            "Epoch 65/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.7823\n",
            "Epoch 66/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4540 - accuracy: 0.7801\n",
            "Epoch 67/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7810\n",
            "Epoch 68/100\n",
            "98/98 [==============================] - 0s 969us/step - loss: 0.4530 - accuracy: 0.7852\n",
            "Epoch 69/100\n",
            "98/98 [==============================] - 0s 988us/step - loss: 0.4524 - accuracy: 0.7830\n",
            "Epoch 70/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.7862\n",
            "Epoch 71/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.7807\n",
            "Epoch 72/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7855\n",
            "Epoch 73/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7846\n",
            "Epoch 74/100\n",
            "98/98 [==============================] - 0s 985us/step - loss: 0.4539 - accuracy: 0.7746\n",
            "Epoch 75/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.7836\n",
            "Epoch 76/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7820\n",
            "Epoch 77/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.7868\n",
            "Epoch 78/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7855\n",
            "Epoch 79/100\n",
            "98/98 [==============================] - 0s 982us/step - loss: 0.4483 - accuracy: 0.7875\n",
            "Epoch 80/100\n",
            "98/98 [==============================] - 0s 968us/step - loss: 0.4526 - accuracy: 0.7807\n",
            "Epoch 81/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7836\n",
            "Epoch 82/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7855\n",
            "Epoch 83/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7836\n",
            "Epoch 84/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7804\n",
            "Epoch 85/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.7849\n",
            "Epoch 86/100\n",
            "98/98 [==============================] - 0s 967us/step - loss: 0.4460 - accuracy: 0.7868\n",
            "Epoch 87/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7891\n",
            "Epoch 88/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7881\n",
            "Epoch 89/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.7830\n",
            "Epoch 90/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7823\n",
            "Epoch 91/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7833\n",
            "Epoch 92/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.7875\n",
            "Epoch 93/100\n",
            "98/98 [==============================] - 0s 999us/step - loss: 0.4438 - accuracy: 0.7942\n",
            "Epoch 94/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7865\n",
            "Epoch 95/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.7846\n",
            "Epoch 96/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.7871\n",
            "Epoch 97/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.7878\n",
            "Epoch 98/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.7865\n",
            "Epoch 99/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7865\n",
            "Epoch 100/100\n",
            "98/98 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.7910\n",
            "63/63 [==============================] - 0s 733us/step - loss: 0.4714 - accuracy: 0.7735\n",
            "[0.47143277525901794, 0.7735000252723694]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.78      0.85      1593\n",
            "           1       0.47      0.76      0.58       407\n",
            "\n",
            "    accuracy                           0.77      2000\n",
            "   macro avg       0.70      0.77      0.71      2000\n",
            "weighted avg       0.83      0.77      0.79      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr_WEh3q26mV"
      },
      "source": [
        "y_pred_final = y_pred1.copy()\n",
        "for i in range(len(y_pred1)):\n",
        "    n_ones = y_pred1[i] + y_pred2[i] + y_pred3[i]+y_pred4[i]\n",
        "    if n_ones>1:\n",
        "        y_pred_final[i] = 1\n",
        "    else:\n",
        "        y_pred_final[i] = 0"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FKyclkL3FFG",
        "outputId": "7bc8256f-3abc-4b0c-92ed-f8261363a233"
      },
      "source": [
        "cl_rep = classification_report(y_test, y_pred_final)\n",
        "print(cl_rep)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.76      0.84      1593\n",
            "           1       0.45      0.78      0.57       407\n",
            "\n",
            "    accuracy                           0.76      2000\n",
            "   macro avg       0.69      0.77      0.70      2000\n",
            "weighted avg       0.83      0.76      0.78      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1zz50_q3jLM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}